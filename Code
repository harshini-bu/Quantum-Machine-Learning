!pip install pennylane
import pennylane as qml
from pennylane import numpy as np
from pennylane.templates import RandomLayers
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

n_epochs = 30   # Number of optimization epochs
n_layers = 1    # Number of random layers
#n_train = 50    # Size of the train dataset
#n_test = 30     # Size of the test dataset

PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH
np.random.seed(0)           # Seed for NumPy random number generator
tf.random.set_seed(0)       # Seed for TensorFlow random number generator




import numpy as np
from tensorflow import keras

# Load the Fashion MNIST dataset
mnist_dataset = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()

# Define the number of samples to use
n_train = 500
n_test = 100

# Reduce dataset size
train_images = train_images[:n_train]
train_labels = train_labels[:n_train]
test_images = test_images[:n_test]
test_labels = test_labels[:n_test]

# Normalize pixel values within 0 and 1
train_images = train_images / 255.0
test_images = test_images / 255.0

# Add extra dimension for convolution channels
train_images = np.expand_dims(train_images, axis=-1)
test_images = np.expand_dims(test_images, axis=-1)



import pennylane as qml
from pennylane.templates import RandomLayers
import numpy as np

# Define the quantum device
dev = qml.device("default.qubit", wires=4)

# Random circuit parameters
n_layers = 3
rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))

# Quantum circuit definition
@qml.qnode(dev)
def circuit(phi):
    # Encoding of 4 classical input values
    for j in range(4):
        qml.RY(np.pi * phi[j], wires=j)

    # Random quantum circuit
    RandomLayers(rand_params, wires=list(range(4)))

    # Measurement producing 4 classical output values
    return [qml.expval(qml.PauliZ(j)) for j in range(4)]

# You can use this circuit function to perform quantum computations



import numpy as np

def quanv(image):
    """Convolves the input image with multiple applications of a quantum circuit."""
    output_shape = (14, 14, 4)
    out = np.zeros(output_shape)

    # Iterate over the top-left pixels of 2x2 squares
    for j in range(0, 28, 2):
        for k in range(0, 28, 2):
            # Extract a 2x2 region from the image
            region = image[j:j+2, k:k+2, 0]
            # Apply a quantum circuit to process the region
            q_results = circuit(region.flatten())
            # Assign the expectation values to different channels of the output pixel
            out[j // 2, k // 2] = q_results

    return out

SAVE_PATH="/content/sample_data/Untitled Folder"
if PREPROCESS == True:
    q_train_images = []
    print("Quantum pre-processing of train images:")
    for idx, img in enumerate(train_images):
        print("{}/{}        ".format(idx + 1, n_train), end="\r")
        q_train_images.append(quanv(img))
    q_train_images = np.asarray(q_train_images)

    q_test_images = []
    print("\nQuantum pre-processing of test images:")
    for idx, img in enumerate(test_images):
        print("{}/{}        ".format(idx + 1, n_test), end="\r")
        q_test_images.append(quanv(img))
    q_test_images = np.asarray(q_test_images)

    # Save pre-processed images
    np.save(SAVE_PATH + "q_train_images.npy", q_train_images)
    np.save(SAVE_PATH + "q_test_images.npy", q_test_images)


# Load pre-processed images
q_train_images = np.load(SAVE_PATH + "q_train_images.npy")
q_test_images = np.load(SAVE_PATH + "q_test_images.npy")

from google.colab import drive
drive.mount('/content/drive')

n_samples = 4
n_channels = 4
fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))
for k in range(n_samples):
    axes[0, 0].set_ylabel("Input")
    if k != 0:
        axes[0, k].yaxis.set_visible(False)
    axes[0, k].imshow(train_images[k, :, :, 0], cmap="gray")

    # Plot all output channels
    for c in range(n_channels):
        axes[c + 1, 0].set_ylabel("Output [ch. {}]".format(c))
        if k != 0:
            axes[c, k].yaxis.set_visible(False)
        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap="gray")

plt.tight_layout()
plt.show()

def MyModel():
    """Initializes and returns a custom Keras model
    which is ready to be trained."""
    model = keras.models.Sequential([
        keras.layers.Flatten(),
        keras.layers.Dense(10, activation="softmax")
    ])

    model.compile(
        optimizer='adam',
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

q_model = MyModel()

q_history = q_model.fit(
    q_train_images,
    train_labels,
    validation_data=(q_test_images, test_labels),
    batch_size=4,
    epochs=n_epochs,
    verbose=2,
)

c_model = MyModel()

c_history = c_model.fit(
    train_images,
    train_labels,
    validation_data=(test_images, test_labels),
    batch_size=4,
    epochs=n_epochs,
    verbose=2,
)



import matplotlib.pyplot as plt

def plot_training_performance(history1, history2, title1, title2):
    fig, axs = plt.subplots(2, 2, figsize=(12, 8))

    # Plot accuracy
    axs[0, 0].plot(history1.history["val_accuracy"], "-ob", label=title1)
    axs[0, 0].plot(history2.history["val_accuracy"], "-og", label=title2)
    axs[0, 0].set_ylabel("Accuracy")
    axs[0, 0].set_ylim([0, 1])
    axs[0, 0].set_xlabel("Epoch")
    axs[0, 0].legend()

    # Plot loss
    axs[1, 0].plot(history1.history["val_loss"], "-ob", label=title1)
    axs[1, 0].plot(history2.history["val_loss"], "-og", label=title2)
    axs[1, 0].set_ylabel("Loss")
    axs[1, 0].set_ylim(top=2.5)
    axs[1, 0].set_xlabel("Epoch")
    axs[1, 0].legend()

    # Plot accuracy (alternative)
    axs[0, 1].plot(history1.history["accuracy"], "-ob", label=title1)
    axs[0, 1].plot(history2.history["accuracy"], "-og", label=title2)
    axs[0, 1].set_ylabel("Accuracy (Training)")
    axs[0, 1].set_ylim([0, 1])
    axs[0, 1].set_xlabel("Epoch")
    axs[0, 1].legend()

    # Plot loss (alternative)
    axs[1, 1].plot(history1.history["loss"], "-ob", label=title1)
    axs[1, 1].plot(history2.history["loss"], "-og", label=title2)
    axs[1, 1].set_ylabel("Loss (Training)")
    axs[1, 1].set_ylim(top=2.5)
    axs[1, 1].set_xlabel("Epoch")
    axs[1, 1].legend()

    plt.tight_layout()
    plt.show()

# Call the function with the appropriate histories and titles
plot_training_performance(q_history, c_history, "With quantum layer", "Without quantum layer")
